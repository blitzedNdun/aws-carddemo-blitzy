# =============================================================================
# Spring Batch ETL Test Configuration Properties
# CardDemo Migration Testing - COBOL to Java Batch Processing Validation
# =============================================================================
# Purpose: Configure Spring Batch ETL jobs for migration testing, ensuring
# chunk sizes, thread pools, error thresholds, and restart policies match
# mainframe batch processing patterns while validating the 4-hour processing window
# =============================================================================

# =============================================================================
# CHUNK PROCESSING CONFIGURATION
# =============================================================================
# Chunk size matches CICS SYNCPOINT intervals for consistent transaction boundaries
# COBOL equivalent: Processing 1000 records before EXEC CICS SYNCPOINT
spring.batch.job.chunk-size=1000

# Commit interval optimized for PostgreSQL bulk operations
# Ensures optimal database performance while maintaining transaction integrity
spring.batch.job.commit-interval=1000

# Page size for cursor-based reading (VSAM STARTBR/READNEXT equivalent)
# Matches PostgreSQL optimal page size for sequential reads
spring.batch.job.page-size=1000

# Skip limit for handling bad records during migration
# Allows processing to continue with data quality issues up to threshold
spring.batch.job.skip-limit=10

# =============================================================================
# PARALLEL PROCESSING CONFIGURATION
# =============================================================================
# Thread pool configuration for concurrent batch processing
# Replicates mainframe parallel job execution capabilities
spring.batch.job.thread-pool.core-size=4
spring.batch.job.thread-pool.max-size=8
spring.batch.job.thread-pool.queue-capacity=100
spring.batch.job.thread-pool.keep-alive-seconds=60

# Parallel step configuration for multi-threaded processing
# Enables concurrent processing of independent data segments
spring.batch.job.parallel-steps=4

# Task executor thread naming pattern for monitoring and debugging
spring.batch.job.thread-name-prefix=batch-etl-

# =============================================================================
# ERROR HANDLING AND RECOVERY CONFIGURATION
# =============================================================================
# Job restart configuration - enables restart from last checkpoint on failure
# Replicates JCL RESTART functionality for batch job resilience
spring.batch.job.restart-enabled=true

# Checkpoint frequency for job restart capability
# Creates recovery points every 5000 records processed
spring.batch.job.checkpoint-frequency=5000

# Maximum retry attempts for transient failures
# Handles temporary database connection issues and recoverable errors
spring.batch.job.retry-limit=3

# Retry delay configuration (milliseconds)
# Exponential backoff for retry attempts
spring.batch.job.retry-delay=1000
spring.batch.job.retry-multiplier=2.0

# Exception handling configuration
# Skip specific exceptions during processing
spring.batch.job.skippable-exceptions=org.springframework.dao.DataIntegrityViolationException,\
  java.text.ParseException,\
  com.carddemo.exception.CobolDataConversionException

# Fatal exceptions that should cause immediate job failure
spring.batch.job.fatal-exceptions=java.lang.OutOfMemoryError,\
  org.springframework.dao.DataAccessResourceFailureException

# =============================================================================
# POSTGRESQL DATABASE OPTIMIZATION
# =============================================================================
# Connection pool configuration for batch processing
# Optimized for high-throughput ETL operations
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000

# PostgreSQL specific optimizations for bulk operations
spring.datasource.hikari.data-source-properties.reWriteBatchedInserts=true
spring.datasource.hikari.data-source-properties.defaultRowFetchSize=1000

# Batch insert/update configuration
# Enables JDBC batch processing for improved performance
spring.jpa.properties.hibernate.jdbc.batch_size=1000
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true

# =============================================================================
# MIGRATION VALIDATION CONFIGURATION
# =============================================================================
# Data validation settings for COBOL-to-Java precision verification
# Ensures BigDecimal calculations match COBOL COMP-3 behavior
spring.batch.validation.precision-tolerance=0.00
spring.batch.validation.rounding-mode=HALF_UP
spring.batch.validation.scale-enforcement=true

# Record count validation between source and target
spring.batch.validation.record-count-check=true
spring.batch.validation.checksum-validation=true

# Data type conversion validation
spring.batch.validation.cobol-conversion-check=true
spring.batch.validation.comp3-precision-check=true

# =============================================================================
# PERFORMANCE MONITORING AND METRICS
# =============================================================================
# Enable detailed metrics collection for performance analysis
# Supports validation of 4-hour batch processing window requirement
spring.batch.metrics.enabled=true
spring.batch.metrics.throughput-monitoring=true
spring.batch.metrics.performance-tracking=true

# Metrics collection intervals (seconds)
spring.batch.metrics.collection-interval=30
spring.batch.metrics.checkpoint-metrics=true

# Performance threshold configuration
# Alert if processing rate falls below minimum throughput
spring.batch.metrics.min-records-per-second=50
spring.batch.metrics.max-processing-time-hours=4

# JVM monitoring for resource utilization
spring.batch.metrics.memory-monitoring=true
spring.batch.metrics.cpu-monitoring=true
spring.batch.metrics.gc-monitoring=true

# =============================================================================
# TEST ENVIRONMENT CONFIGURATION
# =============================================================================
# Test data volume configuration
# Supports different test scenarios with varying data sizes
spring.batch.test.small-dataset-size=10000
spring.batch.test.medium-dataset-size=100000
spring.batch.test.large-dataset-size=1000000
spring.batch.test.stress-dataset-size=10000000

# Test execution timeouts
spring.batch.test.job-timeout-minutes=30
spring.batch.test.step-timeout-minutes=10

# Test data generation settings
spring.batch.test.generate-synthetic-data=true
spring.batch.test.use-production-sample=false
spring.batch.test.anonymize-pii=true

# =============================================================================
# VSAM-TO-POSTGRESQL MIGRATION SETTINGS
# =============================================================================
# File processing configuration for VSAM dataset migration
spring.batch.migration.input-file-encoding=ASCII
spring.batch.migration.output-encoding=UTF-8
spring.batch.migration.fixed-width-processing=true

# VSAM key structure preservation
spring.batch.migration.preserve-key-structure=true
spring.batch.migration.composite-key-handling=true

# Record layout validation
spring.batch.migration.validate-record-length=true
spring.batch.migration.enforce-field-boundaries=true

# =============================================================================
# LOGGING AND AUDITING CONFIGURATION
# =============================================================================
# Enhanced logging for batch job monitoring and troubleshooting
logging.level.org.springframework.batch=DEBUG
logging.level.com.carddemo.batch=DEBUG
logging.level.com.carddemo.migration=DEBUG

# Audit trail configuration
spring.batch.audit.enabled=true
spring.batch.audit.log-level=INFO
spring.batch.audit.include-parameters=true
spring.batch.audit.include-execution-context=true

# Performance logging
spring.batch.logging.performance-logging=true
spring.batch.logging.throughput-logging=true
spring.batch.logging.memory-usage-logging=true

# =============================================================================
# SPRING BATCH INFRASTRUCTURE CONFIGURATION
# =============================================================================
# Job repository configuration for job execution metadata
spring.batch.job.enabled=true
spring.batch.initialize-schema=never
spring.batch.job.names=${spring.batch.job.name:}

# Async processing configuration
spring.batch.job.async-processing=true
spring.batch.job.task-executor-type=thread-pool

# Job execution listener configuration
spring.batch.job.execution-listeners=com.carddemo.batch.listener.PerformanceJobExecutionListener,\
  com.carddemo.batch.listener.MetricsJobExecutionListener,\
  com.carddemo.batch.listener.ValidationJobExecutionListener

# Step execution listener configuration
spring.batch.step.execution-listeners=com.carddemo.batch.listener.ChunkProgressStepListener,\
  com.carddemo.batch.listener.ErrorHandlingStepListener

# =============================================================================
# INTEGRATION TESTING CONFIGURATION
# =============================================================================
# Testcontainers configuration for isolated database testing
spring.batch.test.use-testcontainers=true
spring.batch.test.testcontainers.postgresql.version=16-alpine
spring.batch.test.testcontainers.redis.version=7-alpine

# Test cleanup configuration
spring.batch.test.cleanup-after-test=true
spring.batch.test.preserve-job-repository=false

# Parallel test execution
spring.batch.test.parallel-execution=true
spring.batch.test.max-parallel-jobs=2

# =============================================================================
# COBOL DATA CONVERSION CONFIGURATION
# =============================================================================
# BigDecimal configuration for COBOL COMP-3 precision matching
spring.batch.cobol.decimal-scale-enforcement=true
spring.batch.cobol.default-scale=2
spring.batch.cobol.rounding-mode=HALF_UP

# Character set conversion for EBCDIC/ASCII handling
spring.batch.cobol.character-encoding.source=EBCDIC
spring.batch.cobol.character-encoding.target=UTF-8

# Packed decimal handling
spring.batch.cobol.comp3.validation=true
spring.batch.cobol.comp3.sign-handling=COBOL_STANDARD

# Date format conversion
spring.batch.cobol.date-format.input=yyyyMMdd
spring.batch.cobol.date-format.output=yyyy-MM-dd

# =============================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# =============================================================================
# Development environment settings
spring.profiles.active=test

# CI/CD pipeline configuration
spring.batch.test.ci-mode=false
spring.batch.test.headless-execution=true

# Performance testing mode
spring.batch.test.performance-mode=false
spring.batch.test.load-testing=false

# =============================================================================
# SECURITY CONFIGURATION FOR TESTING
# =============================================================================
# Test security settings (simplified for testing environment)
spring.security.enabled=false
spring.batch.security.job-security-enabled=false

# =============================================================================
# MONITORING INTEGRATION
# =============================================================================
# Actuator endpoints for monitoring batch jobs
management.endpoints.web.exposure.include=health,metrics,info,prometheus,batch
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true

# Custom metrics configuration
management.metrics.tags.application=carddemo-batch
management.metrics.tags.environment=test

# =============================================================================
# VALIDATION THRESHOLDS
# =============================================================================
# 4-hour processing window validation (14400 seconds)
spring.batch.validation.max-processing-time-seconds=14400

# Minimum throughput requirement (records per minute)
spring.batch.validation.min-throughput-rpm=1000

# Memory usage thresholds for performance validation
spring.batch.validation.max-heap-usage-percent=80
spring.batch.validation.max-cpu-usage-percent=85

# Database connection validation
spring.batch.validation.max-connection-pool-usage=90

# =============================================================================
# SPRING BATCH JOB PARAMETERS
# =============================================================================
# Default job parameters for test execution
spring.batch.job.parameters.input.file.path=/test/data/input/
spring.batch.job.parameters.output.file.path=/test/data/output/
spring.batch.job.parameters.archive.file.path=/test/data/archive/
spring.batch.job.parameters.error.file.path=/test/data/error/

# Processing date parameter format
spring.batch.job.parameters.processing.date.format=yyyy-MM-dd
spring.batch.job.parameters.processing.time.format=HH:mm:ss

# =============================================================================
# END OF CONFIGURATION
# =============================================================================
# This configuration ensures comprehensive Spring Batch ETL testing with
# performance monitoring, error handling, and COBOL-to-Java migration validation
# while maintaining compliance with the 4-hour batch processing window requirement
# =============================================================================