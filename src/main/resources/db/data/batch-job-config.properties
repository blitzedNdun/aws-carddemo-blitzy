# =====================================================================================
# Spring Batch Job Configuration Properties for ASCII Data Loading
# =====================================================================================
# Configuration file defining execution parameters, chunk sizes, error handling, and 
# performance tuning for ASCII data loading jobs in the CardDemo application.
# 
# This configuration supports the complete VSAM-to-PostgreSQL data migration with:
# - Chunk-oriented processing using 1000-record chunks per Section 6.2.4.5
# - Fault tolerance and recovery with configurable commit intervals
# - Memory management maintaining usage within 10% increase limit
# - Job execution within 4-hour processing window
# - Comprehensive error handling with exponential backoff and dead letter queue
# - Environment-specific data loading paths and validation thresholds
#
# Technical Specification References:
# - Section 0.1.2: Performance Requirements - Transaction response times under 200ms
# - Section 0.1.3: Technical Interpretation - Service-per-transaction pattern
# - Section 6.2.4.5: Chunk-oriented processing with 1000-record chunks
# - Section 8.3: Containerization - Docker support for batch processing
# =====================================================================================

# =====================================================================================
# CORE BATCH JOB CONFIGURATION
# =====================================================================================
# Primary batch job execution parameters aligned with Spring Boot application.yml
# settings and supporting high-volume ASCII data processing requirements

# Job execution and lifecycle configuration
batch.job.enabled=true
batch.job.auto-restart=true
batch.job.fail-fast=false
batch.job.execution-timeout=14400000
batch.job.instance-timeout=14400000
batch.job.max-concurrent-jobs=3
batch.job.allow-restart=true

# Job repository and metadata configuration
batch.job.repository.enabled=true
batch.job.repository.table-prefix=BATCH_
batch.job.repository.isolation-level=SERIALIZABLE
batch.job.repository.max-varchar-length=2500
batch.job.repository.clobtype=CLOB

# Job launcher configuration
batch.job.launcher.enabled=true
batch.job.launcher.task-executor.core-pool-size=5
batch.job.launcher.task-executor.max-pool-size=10
batch.job.launcher.task-executor.queue-capacity=100
batch.job.launcher.task-executor.keep-alive-seconds=60

# =====================================================================================
# CHUNK PROCESSING CONFIGURATION
# =====================================================================================
# Chunk-oriented processing configuration with 1000-record chunks per Section 6.2.4.5
# Balances memory consumption with commit frequency requirements

# Primary chunk processing settings
batch.chunk.size=1000
batch.chunk.completion-policy=SIMPLE
batch.chunk.reader.save-state=true
batch.chunk.writer.save-state=true
batch.chunk.processor.save-state=true

# Commit interval configuration for transaction boundary management
batch.commit.interval=1000
batch.commit.timeout=30000
batch.commit.synchronization-enabled=true

# Memory management and performance optimization
batch.processing.page-size=1000
batch.processing.prefetch-count=5000
batch.processing.max-items-in-memory=10000
batch.processing.buffer-size=8192

# =====================================================================================
# ERROR HANDLING AND FAULT TOLERANCE
# =====================================================================================
# Comprehensive error handling with exponential backoff and dead letter queue processing
# Ensures reliable batch execution with configurable recovery mechanisms

# Skip policy configuration for data quality issues
batch.skip.enabled=true
batch.skip.limit=100
batch.skip.policy=LIMIT_SKIP_POLICY
batch.skip.exceptions=FlatFileParseException,ValidationException,NumberFormatException,DataIntegrityViolationException

# Retry configuration for transient failures
batch.retry.enabled=true
batch.retry.limit=3
batch.retry.policy=SIMPLE_RETRY_POLICY
batch.retry.exceptions=DataAccessException,TransientDataAccessException,DeadlockLoserDataAccessException

# Exponential backoff configuration
batch.retry.backoff.policy=EXPONENTIAL_BACKOFF_POLICY
batch.retry.backoff.initial-interval=1000
batch.retry.backoff.multiplier=2.0
batch.retry.backoff.max-interval=30000
batch.retry.backoff.max-elapsed-time=300000

# Dead letter queue configuration for failed records
batch.dlq.enabled=true
batch.dlq.table-name=BATCH_DLQ_RECORDS
batch.dlq.max-records=10000
batch.dlq.retention-days=30
batch.dlq.notification.enabled=true

# =====================================================================================
# PERFORMANCE TUNING PARAMETERS
# =====================================================================================
# Memory management and performance optimization maintaining usage within 10% increase
# limit while supporting large batch volumes per performance requirements

# Memory management configuration
batch.memory.max-heap-size=2048m
batch.memory.initial-heap-size=1024m
batch.memory.max-metaspace-size=512m
batch.memory.gc-strategy=G1GC
batch.memory.monitoring.enabled=true
batch.memory.monitoring.threshold=90

# Connection pool optimization for batch processing
batch.datasource.hikari.maximum-pool-size=25
batch.datasource.hikari.minimum-idle=5
batch.datasource.hikari.connection-timeout=30000
batch.datasource.hikari.idle-timeout=600000
batch.datasource.hikari.max-lifetime=1800000
batch.datasource.hikari.leak-detection-threshold=60000

# JDBC batch processing optimization
batch.jdbc.batch-size=1000
batch.jdbc.fetch-size=1000
batch.jdbc.query-timeout=30000
batch.jdbc.update-batch-size=1000
batch.jdbc.statement-cache-size=100

# =====================================================================================
# DATA VALIDATION AND QUALITY CONFIGURATION
# =====================================================================================
# Validation thresholds and data quality checks for ASCII data processing
# Ensures data integrity during VSAM-to-PostgreSQL migration

# Field validation configuration
batch.validation.enabled=true
batch.validation.strict-mode=true
batch.validation.null-field-policy=SKIP
batch.validation.empty-field-policy=SKIP
batch.validation.date-format=yyyy-MM-dd
batch.validation.decimal-precision=12
batch.validation.decimal-scale=2

# Business rule validation thresholds
batch.validation.account-id.pattern=^[0-9]{11}$
batch.validation.customer-id.pattern=^[0-9]{9}$
batch.validation.card-number.pattern=^[0-9]{16}$
batch.validation.transaction-amount.max=999999999.99
batch.validation.transaction-amount.min=-999999999.99

# Data quality monitoring
batch.quality.monitoring.enabled=true
batch.quality.error-rate.threshold=5.0
batch.quality.duplicate-detection.enabled=true
batch.quality.referential-integrity.enabled=true

# =====================================================================================
# ENVIRONMENT-SPECIFIC CONFIGURATION
# =====================================================================================
# Environment-specific data loading paths and configuration parameters
# Supporting deployment across development, staging, and production environments

# Data file path configuration
batch.data.base-path=classpath:db/data
batch.data.input.encoding=UTF-8
batch.data.output.encoding=UTF-8
batch.data.file.permissions=644

# ASCII data file configurations
batch.data.account.file-path=${batch.data.base-path}/acctdata.txt
batch.data.account.record-length=300
batch.data.account.expected-records=50
batch.data.account.chunk-size=50

batch.data.customer.file-path=${batch.data.base-path}/custdata.txt
batch.data.customer.record-length=312
batch.data.customer.expected-records=500
batch.data.customer.chunk-size=100

batch.data.card.file-path=${batch.data.base-path}/carddata.txt
batch.data.card.record-length=150
batch.data.card.expected-records=100
batch.data.card.chunk-size=100

batch.data.transaction.file-path=${batch.data.base-path}/dailytran.txt
batch.data.transaction.record-length=189
batch.data.transaction.expected-records=1000
batch.data.transaction.chunk-size=1000

# Reference data file configurations
batch.data.reference.tcatbal.file-path=${batch.data.base-path}/tcatbal.txt
batch.data.reference.discgrp.file-path=${batch.data.base-path}/discgrp.txt
batch.data.reference.trantype.file-path=${batch.data.base-path}/trantype.txt
batch.data.reference.trancatg.file-path=${batch.data.base-path}/trancatg.txt
batch.data.reference.cardtyp.file-path=${batch.data.base-path}/cardtyp.txt
batch.data.reference.chunk-size=50

# =====================================================================================
# COBOL PRECISION AND NUMERIC HANDLING
# =====================================================================================
# Configuration for exact COBOL COMP-3 decimal precision preservation
# Ensures identical financial calculations using BigDecimal arithmetic

# BigDecimal configuration for COBOL COMP-3 precision
batch.decimal.math-context=DECIMAL128
batch.decimal.rounding-mode=HALF_EVEN
batch.decimal.default-scale=2
batch.decimal.max-precision=31
batch.decimal.strip-trailing-zeros=false

# Financial calculation configuration
batch.financial.currency.code=USD
batch.financial.currency.precision=2
batch.financial.interest-rate.precision=6
batch.financial.amount.validation.enabled=true
batch.financial.balance.validation.enabled=true

# Date and time handling configuration
batch.datetime.default-timezone=UTC
batch.datetime.cobol-date-format=yyyy-MM-dd
batch.datetime.timestamp-format=yyyy-MM-dd HH:mm:ss.SSSSSS
batch.datetime.leap-year.handling=COBOL_COMPATIBLE

# =====================================================================================
# MONITORING AND METRICS CONFIGURATION
# =====================================================================================
# Comprehensive monitoring and metrics collection for batch job execution
# Supports performance analysis and operational monitoring

# Metrics collection configuration
batch.metrics.enabled=true
batch.metrics.export.prometheus.enabled=true
batch.metrics.export.jmx.enabled=true
batch.metrics.collection.interval=60000
batch.metrics.retention.days=30

# Performance monitoring configuration
batch.monitoring.execution-time.enabled=true
batch.monitoring.memory-usage.enabled=true
batch.monitoring.throughput.enabled=true
batch.monitoring.error-rate.enabled=true
batch.monitoring.progress.enabled=true

# Alerting configuration
batch.alerting.enabled=true
batch.alerting.execution-time.threshold=3600000
batch.alerting.error-rate.threshold=5.0
batch.alerting.memory-usage.threshold=90.0
batch.alerting.webhook.enabled=false

# =====================================================================================
# LOGGING CONFIGURATION
# =====================================================================================
# Structured logging configuration for batch job execution tracking
# Supports debugging and audit trail requirements

# Batch-specific logging configuration
batch.logging.enabled=true
batch.logging.level=INFO
batch.logging.structured.enabled=true
batch.logging.audit.enabled=true
batch.logging.performance.enabled=true

# Log file configuration
batch.logging.file.enabled=true
batch.logging.file.path=logs/batch
batch.logging.file.max-size=100MB
batch.logging.file.max-history=30
batch.logging.file.pattern=%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%logger{36}] - %msg%n

# Progress logging configuration
batch.logging.progress.interval=1000
batch.logging.progress.include-memory=true
batch.logging.progress.include-timing=true
batch.logging.progress.include-throughput=true

# =====================================================================================
# SECURITY CONFIGURATION
# =====================================================================================
# Security settings for batch job execution and data protection
# Ensures compliance with data protection requirements

# Access control configuration
batch.security.enabled=true
batch.security.require-authentication=true
batch.security.allowed-roles=BATCH_USER,ADMIN
batch.security.job-execution.audit=true

# Data protection configuration
batch.security.data.encryption.enabled=false
batch.security.data.masking.enabled=true
batch.security.data.masking.pii-fields=firstName,lastName,ssn,phoneNumber
batch.security.data.retention.days=2555

# Audit logging configuration
batch.security.audit.enabled=true
batch.security.audit.log-file=logs/batch-audit.log
batch.security.audit.include-data-access=true
batch.security.audit.include-job-parameters=true

# =====================================================================================
# CIRCUIT BREAKER CONFIGURATION
# =====================================================================================
# Circuit breaker settings for fault tolerance and system protection
# Prevents cascading failures during batch processing

# Circuit breaker configuration
batch.circuit-breaker.enabled=true
batch.circuit-breaker.failure-rate-threshold=50
batch.circuit-breaker.slow-call-rate-threshold=50
batch.circuit-breaker.slow-call-duration-threshold=2000
batch.circuit-breaker.permitted-calls-in-half-open-state=3
batch.circuit-breaker.minimum-calls=10
batch.circuit-breaker.wait-duration-in-open-state=10000
batch.circuit-breaker.sliding-window-size=10
batch.circuit-breaker.sliding-window-type=COUNT_BASED

# Bulkhead configuration for resource isolation
batch.bulkhead.enabled=true
batch.bulkhead.max-concurrent-calls=10
batch.bulkhead.max-wait-duration=1000

# =====================================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# =====================================================================================
# Environment-specific configuration overrides for deployment flexibility

# Development environment overrides
batch.dev.chunk.size=100
batch.dev.commit.interval=100
batch.dev.skip.limit=50
batch.dev.retry.limit=5
batch.dev.logging.level=DEBUG

# Staging environment overrides
batch.staging.chunk.size=500
batch.staging.commit.interval=500
batch.staging.skip.limit=25
batch.staging.retry.limit=3
batch.staging.logging.level=INFO

# Production environment overrides
batch.prod.chunk.size=1000
batch.prod.commit.interval=1000
batch.prod.skip.limit=10
batch.prod.retry.limit=3
batch.prod.logging.level=INFO
batch.prod.metrics.enabled=true
batch.prod.alerting.enabled=true

# =====================================================================================
# INTEGRATION CONFIGURATION
# =====================================================================================
# Integration settings for external systems and message queues
# Supports event-driven batch processing and notifications

# Event publishing configuration
batch.events.enabled=true
batch.events.publisher.async=true
batch.events.job-started.enabled=true
batch.events.job-completed.enabled=true
batch.events.job-failed.enabled=true
batch.events.step-completed.enabled=true

# Message queue configuration
batch.messaging.enabled=false
batch.messaging.queue.job-events=batch.job.events
batch.messaging.queue.error-notifications=batch.error.notifications
batch.messaging.queue.progress-updates=batch.progress.updates

# External system integration
batch.external.notification.enabled=false
batch.external.notification.webhook.url=
batch.external.notification.retry.attempts=3
batch.external.notification.timeout=5000

# =====================================================================================
# CONFIGURATION VALIDATION
# =====================================================================================
# Configuration validation and startup checks
# Ensures proper configuration before batch job execution

# Validation settings
batch.validation.config.enabled=true
batch.validation.config.strict=true
batch.validation.config.fail-fast=true

# Required configuration validation
batch.validation.required.datasource=true
batch.validation.required.job-repository=true
batch.validation.required.file-paths=true
batch.validation.required.chunk-size=true

# Performance validation
batch.validation.performance.max-chunk-size=10000
batch.validation.performance.min-chunk-size=1
batch.validation.performance.max-memory-usage=4096
batch.validation.performance.max-execution-time=14400000

# =====================================================================================
# NOTES AND RECOMMENDATIONS
# =====================================================================================
# 1. Chunk size of 1000 records balances memory usage with transaction performance
# 2. Skip limit of 100 allows processing to continue with data quality issues
# 3. Retry limit of 3 with exponential backoff handles transient failures
# 4. Memory monitoring prevents OutOfMemoryError during large batch processing
# 5. Dead letter queue captures failed records for manual review and reprocessing
# 6. Circuit breaker prevents cascading failures during database connectivity issues
# 7. Environment-specific overrides support different deployment requirements
# 8. Security configuration ensures proper access control and audit logging
# 9. Metrics integration supports operational monitoring and alerting
# 10. COBOL precision preservation ensures exact financial calculation equivalence